### **Deep Research Agentic Bot - Project Overview**  

The **Deep Research Agentic Bot** is an AI-powered research assistant designed to **automate academic research** by searching for papers, extracting references, analyzing citations, summarizing content, and generating structured literature reviews.  

---

## **ğŸ”¹ Project Purpose**
The project aims to **reduce the manual effort** in research by:
1. **Finding relevant papers** on a given topic from Google Scholar.
2. **Extracting and analyzing references** to identify key citations.
3. **Downloading open-access papers** automatically using DOIs.
4. **Summarizing research papers** using AI (Google Gemini).
5. **Building a knowledge graph** to represent relationships between papers.
6. **Generating a structured literature review** with AI assistance.

---

## **ğŸ”¹ Key Components**
The system consists of multiple agents, each responsible for a specific research task:

### **1ï¸âƒ£ Search & Selection Agent**
- Queries **Google Scholar** for relevant papers.
- Displays a **selection interface** for users to choose papers.

### **2ï¸âƒ£ Paper Downloader Agent**
- Extracts **DOIs** from selected papers.
- Searches for full-text PDFs in **Semantic Scholar, OpenAlex, and arXiv**.
- Falls back to **Sci-Hub** if needed.

### **3ï¸âƒ£ Reference Extractor Agent**
- Reads **references** from research papers.
- Uses **CrossRef API** to validate citations and retrieve more DOIs.

### **4ï¸âƒ£ Knowledge Graph Builder**
- Uses **Natural Language Processing (NLP)** to extract **key topics** from papers.
- Constructs a **graph** of related research using **network analysis**.

### **5ï¸âƒ£ Summarization Agent**
- Extracts **key findings, figures, and tables** from papers.
- Uses **Google Gemini AI** to summarize research papers in a structured format.

### **6ï¸âƒ£ Literature Review Generator**
- Compiles research insights into a **formatted literature review**.
- Identifies **key themes, gaps, and conclusions**.

---

## **ğŸ”¹ How It Works**
1. **User inputs a research topic** (e.g., "AI in Healthcare").
2. **System fetches relevant papers** from Google Scholar.
3. **User selects papers**, and PDFs are automatically downloaded.
4. **References are extracted**, and additional cited papers are retrieved.
5. **A knowledge graph is built**, connecting related papers.
6. **Summaries are generated** for all collected papers.
7. **A literature review is compiled** and formatted for use in research.

---

## **ğŸ”¹ Why This Project is Useful**
âœ… **Saves time** by automating the tedious research process.  
âœ… **Expands knowledge** by recursively finding cited papers.  
âœ… **Enhances understanding** through structured AI-generated summaries.  
âœ… **Helps researchers & students** by auto-generating literature reviews.  

This tool is especially useful for **researchers, students, and professionals** who need to quickly explore academic topics and generate reports efficiently. ğŸš€

## **ğŸ“Œ Features**
- **Search & Select Papers** ğŸ“š: Finds relevant academic papers from Google Scholar.  
- **Multi-Level Reference Mining** ğŸ”: Extracts references from papers and recursively downloads cited works.  
- **Paper Download Automation** ğŸ“„: Retrieves open-access PDFs from multiple sources (Semantic Scholar, OpenAlex, arXiv, Sci-Hub fallback).  
- **Knowledge Graph Creation** ğŸ§ : Builds a graph of related research papers based on keyword similarity.  
- **AI-Powered Summarization** ğŸ¤–: Uses **Google Gemini AI** to generate structured summaries of research papers.  
- **Automated Literature Review** ğŸ“‘: Generates a formatted literature review from extracted research papers.  
- **Streamlit UI** ğŸ›ï¸: Provides an intuitive web-based interface for easy interaction.  

---

## **ğŸ› ï¸ Tech Stack**
- **Backend**: Python  
- **Frontend**: Streamlit  
- **AI Models**: Google Gemini, SentenceTransformers  
- **Data Extraction**: PyMuPDF, pdfplumber  
- **Knowledge Graph**: NetworkX  
- **API Integration**: Semantic Scholar, OpenAlex, CrossRef  
- **Cloud Deployment**: GCP Cloud Run (or other options)  

---

## **ğŸš€ Setup & Installation**
### **ğŸ”¹ 1. Clone the Repository**
```bash
git clone https://github.com/saimanojbera/Deep_Research_Agent.git
cd deep-research-bot
```

### **ğŸ”¹ 2. Create a Virtual Environment (Optional)**
```bash
python -m venv venv
source venv/bin/activate   # For macOS/Linux
venv\Scripts\activate      # For Windows
```

### **ğŸ”¹ 3. Install Dependencies**
```bash
pip install -r requirements.txt
```

### **ğŸ”¹ 4. Set Up API Keys**
Create a `.env` file and add the required API keys:
```plaintext
SERPERDEV_API_KEY=your_serper_api_key
GEMINI_API_KEY=your_gemini_api_key
```

---

## **ğŸ–¥ï¸ Running the Application Locally**
```bash
streamlit run app.py
```
- Open **http://localhost:8501/** in your browser.

---

## **ğŸ“‚ Project Structure**
```
ğŸ“¦ deep-research-bot
â”œâ”€â”€ ğŸ“œ app.py                      # Main Streamlit app
â”œâ”€â”€ ğŸ“œ copy_files.py                # Handles file movement
â”œâ”€â”€ ğŸ“œ Knowledge_Graph.py           # Creates research knowledge graph
â”œâ”€â”€ ğŸ“œ Paper_downloader_Agent.py    # Downloads papers using DOIs
â”œâ”€â”€ ğŸ“œ Referece_extractor_agent.py   # Extracts references from papers
â”œâ”€â”€ ğŸ“œ Summariser_agent.py          # AI-based summarization
â”œâ”€â”€ ğŸ“œ Writer_agent.py              # Generates literature review
â”œâ”€â”€ ğŸ“‚ Collected_Papers/            # Stores all downloaded papers
â”œâ”€â”€ ğŸ“‚ references_json/             # Extracted references in JSON format
â”œâ”€â”€ ğŸ“‚ structured_summaries/        # AI-generated summaries
â”œâ”€â”€ ğŸ“œ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“œ Dockerfile                   # Deployment container config
â”œâ”€â”€ ğŸ“œ README.md                    # This file
```